{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from typing import Literal\n",
    "from operator import itemgetter\n",
    "from typing_extensions import TypedDict\n",
    "from dotenv import load_dotenv\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAI, ChatOpenAI\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv('LANGCHAIN_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third-party data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "source data -> text loader -> embedding vector -> store vectors -> retrieve vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TODO: add third-party data\n",
    "# loader = TextLoader(\"./data/recipes.json\")\n",
    "# index = VectorstoreIndexCreator(embedding=OpenAIEmbeddings()).from_loaders([loader]) \n",
    "\n",
    "# data = loader.load()\n",
    "# text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "# all_splits = text_splitter.split_documents(data)\n",
    "# vectorstore = Chroma.from_documents(documents=all_splits, embedding=OpenAIEmbeddings())\n",
    "\n",
    "# # k is the number of chunks to retrieve\n",
    "# k = 4\n",
    "# retriever = vectorstore.as_retriever(k=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"How to make Classic Margherita Pizza?\"\n",
    "# result = index.query_with_sources(query, llm=OpenAI())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build chains for 4 use cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chain_creator(llm, prompt_template):\n",
    "    return prompt_template | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define prompt templates for each service\n",
    "tourist_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are an expert in finding tourist attractions.\"),\n",
    "        (\"human\", \"Find top tourist attractions in {location}.\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "itinerary_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are an expert in travel itinerary planning.\"),\n",
    "        (\"human\", \"Create a 3-day itinerary for a visit to {location}.\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "restaurant_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are an expert in recommending restaurants.\"),\n",
    "        (\"human\", \"Suggest restaurants in {location} that offer {cuisine}.\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "travel_ideas_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are an expert in recommending travel ideas.\"),\n",
    "        (\"human\", \"Recommend travel destinations for someone interested in {interests}.\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create chains for each service\n",
    "tourist_chain = chain_creator(llm, tourist_prompt)\n",
    "itinerary_chain = chain_creator(llm, itinerary_prompt)\n",
    "restaurant_chain = chain_creator(llm, restaurant_prompt)\n",
    "travel_ideas_chain = chain_creator(llm, travel_ideas_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Route an input query to a specific chain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the routing system\n",
    "class RouteQuery(TypedDict):\n",
    "    \"\"\"Route query to the appropriate destination.\"\"\"\n",
    "    destination: Literal[\n",
    "        \"Tourist Attraction\", \n",
    "        \"Itinerary Planning\", \n",
    "        \"Restaurant Recommendations\", \n",
    "        \"Exploring Travel Ideas\"\n",
    "    ]\n",
    "\n",
    "route_system = \"Route the user's query to either 'Tourist Attraction', 'Itinerary Planning', 'Restaurant Recommendations', or 'Exploring Travel Ideas'.\"\n",
    "\n",
    "route_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", route_system),\n",
    "        (\"human\", \"{query}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Routing chain based on the query\n",
    "route_chain = route_prompt | llm.with_structured_output(RouteQuery) | itemgetter(\"destination\")\n",
    "\n",
    "# TODO: ParsedQuery output type based on usage\n",
    "class ParsedQuery(TypedDict):\n",
    "    \"\"\"Extracted information from a natural language query.\"\"\"\n",
    "    location: str\n",
    "    cuisine: str\n",
    "\n",
    "# Step 1: Create a parsing chain to extract structured data (e.g., location, cuisine) from the natural language query\n",
    "parse_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are an expert travel assistant. Extract relevant information like location and cuisine from the query.\"),\n",
    "        (\"human\", \"{query}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Chain to extract structured information from the natural query\n",
    "parse_chain = parse_prompt | llm.with_structured_output(ParsedQuery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: simplify this paragraph\n",
    "# Final chain that routes to the appropriate LLM chain based on user input\n",
    "def get_chain_for_service(service_type, query):\n",
    "    if service_type == \"Tourist Attraction\":\n",
    "        # Expecting 'location' variable\n",
    "        return tourist_chain.invoke({\"location\": query.get(\"location\")})\n",
    "    elif service_type == \"Itinerary Planning\":\n",
    "        # Expecting 'location' variable\n",
    "        return itinerary_chain.invoke({\"location\": query.get(\"location\")})\n",
    "    elif service_type == \"Restaurant Recommendations\":\n",
    "        # Expecting 'location' and 'cuisine' variables\n",
    "        return restaurant_chain.invoke({\"location\": query.get(\"location\"), \"cuisine\": query.get(\"cuisine\")})\n",
    "    elif service_type == \"Exploring Travel Ideas\":\n",
    "        # Expecting 'interests' variable\n",
    "        return travel_ideas_chain.invoke({\"interests\": query.get(\"interests\")})\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown service type: {service_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all the steps into the final chain\n",
    "final_chain = {\n",
    "    \"destination\": route_chain,\n",
    "    \"query\": parse_chain\n",
    "} | RunnableLambda(\n",
    "    # Final step: Route to the correct service and invoke the right chain\n",
    "    lambda x: get_chain_for_service(x[\"destination\"], x['query'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: Here are some popular Italian restaurants in New York City:\n",
      "\n",
      "1. Carbone - Located in Greenwich Village, Carbone offers classic Italian-American dishes in a stylish, retro setting.\n",
      "2. L'Artusi - This West Village spot serves up modern Italian cuisine in a chic, bustling atmosphere.\n",
      "3. Via Carota - A cozy Italian trattoria in the West Village known for its rustic dishes and welcoming ambiance.\n",
      "4. Lupa - Mario Batali's Roman-inspired trattoria in Greenwich Village is a favorite for pasta lovers.\n",
      "5. Marea - For upscale Italian seafood, check out Marea in Midtown Manhattan for a refined dining experience.\n",
      "6. Il Buco - A Noho institution known for its seasonal, Mediterranean-inspired Italian fare and charming atmosphere.\n",
      "7. Don Angie - This West Village gem offers a modern take on Italian-American cuisine with a creative twist.\n",
      "8. Rubirosa - Located in Nolita, Rubirosa is a cozy spot known for its thin-crust pizza and classic Italian dishes.\n",
      "9. Eataly - For a one-stop shop for all things Italian, visit Eataly in the Flatiron District for a variety of dining options and gourmet products.\n",
      "10. L'Artusi - A bustling West Village spot serving up modern Italian cuisine in a chic, contemporary setting.\n",
      "\n",
      "These are just a few of the many fantastic Italian restaurants in New York City that you can explore and enjoy!\n"
     ]
    }
   ],
   "source": [
    "# Example query usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Example of a natural language query\n",
    "    inout_query = {\n",
    "        \"query\": \"Please list the top 3 Italian restaurants in New York\"\n",
    "    }\n",
    "    \n",
    "    # Pass the natural language query to the final chain\n",
    "    response = final_chain.invoke(inout_query)\n",
    "    print(f\"Response: {response}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
